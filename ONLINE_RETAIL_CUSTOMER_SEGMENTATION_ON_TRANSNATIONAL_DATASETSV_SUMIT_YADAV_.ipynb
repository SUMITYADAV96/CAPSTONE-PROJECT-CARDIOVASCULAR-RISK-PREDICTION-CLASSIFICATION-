{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ONLINE RETAIL CUSTOMER SEGMENTATION ON TRANSNATIONAL DATASETSV - SUMIT YADAV .ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPgwvzgBXCez1jSmSAU2sBG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SUMITYADAV96/CAPSTONE-PROJECT-CARDIOVASCULAR-RISK-PREDICTION-CLASSIFICATION-/blob/main/ONLINE_RETAIL_CUSTOMER_SEGMENTATION_ON_TRANSNATIONAL_DATASETSV_SUMIT_YADAV_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Identification of major customer segments on a transnational dataset. </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### In this project, your task is to identify major customer segments on a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "* ### InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "* ### StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "* ### Description: Product (item) name. Nominal.\n",
        "* ### Quantity: The quantities of each product (item) per transaction. Numeric.\n",
        "* ### InvoiceDate: Invoice Date and time. Numeric, the day and time when each transaction was generated.\n",
        "* ### UnitPrice: Unit price. Numeric, Product price per unit in sterling.\n",
        "* ### CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "* ### Country: Country name. Nominal, the name of the country where each customer resides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkoxnUDL0JZd"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr4R0HVABMiy"
      },
      "source": [
        "## **Importing and Inspecting Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9hv1Z-a0yUU"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "%matplotlib inline\n",
        "from scipy.cluster.hierarchy import dendrogram,linkage\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0iS1GPoLP4ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QWoQU5vRSk6"
      },
      "outputs": [],
      "source": [
        "# Defining url of saved csv file\n",
        "url ='/content/drive/MyDrive/CAPSTONE PROJECT SUBMISSION FOLDER/CLUSTERING ANALYSIS ON UK -BASED INDUSTRIES - SUMIT YADAV/Online Retail.csv'\n",
        "\n",
        "# Importing dataset to create a dataframe\n",
        "df = pd.read_csv(url, encoding=\"unicode_escape\", parse_dates=[\"InvoiceDate\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT_LefXj16ja"
      },
      "outputs": [],
      "source": [
        "# Checking shape of dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQb9DhMq16jb"
      },
      "outputs": [],
      "source": [
        "# Checking top 5 records\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj1-eZcSHsDM"
      },
      "outputs": [],
      "source": [
        "# Checking bottom 5 records\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sHFffo3sRc1"
      },
      "outputs": [],
      "source": [
        "# Checking all the columns present in the dataset\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7tB5VysuNJc"
      },
      "outputs": [],
      "source": [
        "# Basic Info of the dataset\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3AP1Y8vDwwJ"
      },
      "outputs": [],
      "source": [
        "# Descriptive Statistics\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMxJym6pTLee"
      },
      "outputs": [],
      "source": [
        "# Checking number of unique values in each column\n",
        "for col in df.columns:\n",
        "  print(col,':',df[col].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_MLTvKRw1d0"
      },
      "source": [
        "##**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8evobL5vvFv"
      },
      "outputs": [],
      "source": [
        "# Missing data counts and percentage\n",
        "missing = df.columns[df.isnull().any()].tolist()\n",
        "\n",
        "print('Missing Data Count')\n",
        "print(df[missing].isnull().sum().sort_values(ascending = False))\n",
        "print('--'*12)\n",
        "print('Missing Data Percentage')\n",
        "print(round(df[missing].isnull().sum().sort_values(ascending = False)/len(df)*100,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSM7m-g2UVH3"
      },
      "outputs": [],
      "source": [
        "# Dropping the rows with nulls\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91Vu9ceYFnVT"
      },
      "outputs": [],
      "source": [
        "# Checking duplicates\n",
        "print(len(df[df.duplicated()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFNvMHnVvs9S"
      },
      "outputs": [],
      "source": [
        "# Dropping duplicate rows\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7JgPqw4VQ9e"
      },
      "outputs": [],
      "source": [
        "# New Shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxWIwkLUWGT5"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XkENqnTdiS5"
      },
      "outputs": [],
      "source": [
        "# Creating new features from the datetime column InvoiceDate\n",
        "df[\"year\"]= df[\"InvoiceDate\"].apply(lambda x: x.year)\n",
        "df['Month']= df['InvoiceDate'].apply(lambda x: x.month_name())\n",
        "df['Day']= df['InvoiceDate'].apply(lambda x: x.day_name())\n",
        "df[\"hour\"]= df[\"InvoiceDate\"].apply(lambda x: x.hour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgT22LWZYIDr"
      },
      "outputs": [],
      "source": [
        "# Creating a new feature 'TotalAmount' by multiplying Quantity and UnitPrice\n",
        "df['TotalAmount'] = df['Quantity']*df['UnitPrice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SVeL7aNGe8H"
      },
      "outputs": [],
      "source": [
        "# Creating a new feature 'TimeType' based on hours to define whether its Morning,Afternoon or Evening\n",
        "df['TimeType'] = np.where((df[\"hour\"]>5)&(df[\"hour\"]<18), np.where(\n",
        "                           df[\"hour\"]<12, 'Morning','Afternoon'),'Evening')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-3ilmvjX7uo"
      },
      "outputs": [],
      "source": [
        "# Checking the number of cancellations by each customer. InvoiceNo starting with 'C' represents cancellation\n",
        "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n",
        "cancellations = df[df['InvoiceNo'].str.contains('C')].groupby('CustomerID')[['InvoiceNo']].count()\n",
        "\n",
        "# Renaming the columns and checking top 5 cancellations\n",
        "cancellations.rename(columns={'InvoiceNo': 'Cancellations'}, inplace=True)\n",
        "cancellations.sort_values(by=['Cancellations'], ascending=False).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uPqt8DKWqAx"
      },
      "outputs": [],
      "source": [
        "# Dropping cancellations from the main dataframe\n",
        "df = df[~df['InvoiceNo'].str.contains('C')]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "1i9Sl2b1HiLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VF4jhnXlHkk4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}